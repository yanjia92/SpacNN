未完成
    ???给定一个置信度为0.05的置信区间，如何计算所需样本的大小。
    1. 用户可以选择prism true data to print or not.
        在进入predict界面时用户可以选择要打印的prism数据文本文件
            文本文件格式 第一行是所有数据的文字定义 之后的每一行分别是数据

    2. bug 设置训练数据,中途退出,依旧进行训练

已完成
如何确保expression的parsing是正确的？ 单元测试成功 testParseExpr.py
增加label, 测试label testLabel.py单元测试成功
修改command语法规则, 增加name解析
比较了parsed model和built model之间的异同, 即check了两个模型在相同的天数下各个模块的损坏概率, 结果是相同.
提前计算每个day对应的failure probability.(在prepareCommands中进行计算, 异步计算)：发现可以提高效率，parsed model和built model模型产生随机路径时间基本相同，大约为0.06s.
Fix "Running checker on built model produces different result with PRISM" bug
验证parsed model在regressor中的正确性
        1. 测试合理的checker.c and checker.d 使得验证的结果相对准确 testcheckingalgo.py
        2. 测试parsed model的正确性
(testcheckingalgo.py succeed on windows)

在本机安装python2.7 pip etc
在D:\ENV27\ 下安装虚拟环境，安装wxPython pyFormUI https://github.com/jeffchau1979/pyFormUI
安装matplotlib
配置pycharm 使用ENV27虚拟环境
LTL公式的输入 UI 不带解析的ltl input finished. yes
训练好的network 序列化
ltl解析
输入LTL不要打回车就直接调用函数
    这里的ltl解析放到用户按train的按钮时再调用
用户输入超参数
    超参数: 取样数目 神经网络隐藏层神经元个数 学习率 矫正率
测试checker验证CTMC的正确性(finished)



不足
目前command的update部分不允许出现boolean_expression
因为在parse module的时候, 默认将所有的boolean_expression解析为当前command的guard


测试对偶变量能否减小smc结果的方差。
普通smc算法的结果：
对于toy model，每个样本抽取100条路径，产生20个样本，方差为0.001左右。
同样对于toy model，采用antithetic variables采样方法后，每个样本的路径数保持不变，方差减小了4到5倍。


测试给样本加权重与不加权重的拟合的效果差别
首先针对训练数据，不加权重进行拟合。
实验方案：采取不同训练参数对训练数据进行拟合，根据PRISM真数据计算出平均偏差。


验证antithetic variable确实可以减少方差
两种SMC算法各取1000个样本，比较方差


